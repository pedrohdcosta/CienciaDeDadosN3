{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Projeto N3 - Predi√ß√£o de Churn de Clientes Telco\n",
    "\n",
    "## Ci√™ncia de Dados - Avalia√ß√£o Final\n",
    "\n",
    "**Autor:** Pedro Henrique Costa  \n",
    "**Dataset:** Telco Customer Churn  \n",
    "**Objetivo:** Prever se um cliente vai cancelar o servi√ßo (churn)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: O Problema de Neg√≥cio (1,0 ponto)\n",
    "\n",
    "## 1.1 Dom√≠nio do Problema\n",
    "\n",
    "Este projeto se insere no contexto do **setor de telecomunica√ß√µes**, um mercado altamente competitivo onde a reten√ß√£o de clientes √© fundamental para a sustentabilidade do neg√≥cio. O fen√¥meno de **churn** (cancelamento de servi√ßos) representa um dos maiores desafios para empresas de telecom, pois:\n",
    "\n",
    "- **Custo de aquisi√ß√£o vs reten√ß√£o:** Conquistar um novo cliente custa de 5 a 25 vezes mais do que manter um existente\n",
    "- **Impacto na receita:** A perda de clientes afeta diretamente o faturamento recorrente\n",
    "- **Competitividade:** Com muitas op√ß√µes no mercado, clientes insatisfeitos migram facilmente para concorrentes\n",
    "\n",
    "## 1.2 Pergunta de Neg√≥cio\n",
    "\n",
    "> **\"Quais fatores t√™m maior impacto na decis√£o de um cliente cancelar o servi√ßo de telecomunica√ß√µes?\"**\n",
    "\n",
    "Esta pergunta guia nossa an√°lise e modelagem, buscando identificar padr√µes comportamentais e caracter√≠sticas que indicam propens√£o ao churn.\n",
    "\n",
    "## 1.3 Objetivo do Modelo\n",
    "\n",
    "O objetivo √© construir um **modelo de classifica√ß√£o** capaz de:\n",
    "\n",
    "1. **Prever churn:** Identificar clientes com alta probabilidade de cancelamento antes que isso aconte√ßa\n",
    "2. **Possibilitar a√ß√µes preventivas:** Permitir que a equipe de reten√ß√£o atue proativamente com ofertas e benef√≠cios personalizados\n",
    "3. **Reduzir custos:** Minimizar perdas financeiras associadas ao cancelamento de contratos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso!\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 2: Pipeline de Dados (1,0 ponto)\n",
    "\n",
    "## 2.1 Origem e Arquitetura de Dados\n",
    "\n",
    "### Fonte Original\n",
    "- **Dataset:** Telco Customer Churn\n",
    "- **Origem:** IBM Sample Data Sets / Kaggle\n",
    "- **Formato:** CSV com 7.043 registros e 21 colunas\n",
    "\n",
    "### Arquitetura de Armazenamento: Data Lakehouse\n",
    "\n",
    "Optamos pela arquitetura **Data Lakehouse**, que combina:\n",
    "- **Flexibilidade do Data Lake:** Armazenamento de dados brutos em formato original\n",
    "- **Estrutura√ß√£o do Data Warehouse:** Dados tratados e prontos para an√°lise\n",
    "\n",
    "```\n",
    "üìÅ data/\n",
    "‚îú‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv  (dados brutos)\n",
    "‚îî‚îÄ‚îÄ [dados processados em mem√≥ria durante an√°lise]\n",
    "```\n",
    "\n",
    "## 2.2 Pipeline de Dados\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  INGEST√ÉO   ‚îÇ => ‚îÇ   LIMPEZA   ‚îÇ => ‚îÇ     EDA     ‚îÇ => ‚îÇ PREPARA√á√ÉO  ‚îÇ\n",
    "‚îÇ  CSV Load   ‚îÇ    ‚îÇ  Transform  ‚îÇ    ‚îÇ  An√°lise    ‚îÇ    ‚îÇ  Encoding   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Ingest√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset\n",
    "# Tentamos m√∫ltiplos caminhos para garantir compatibilidade\n",
    "possible_paths = [\n",
    "    '../data/WA_Fn-UseC_-Telco-Customer-Churn.csv',\n",
    "    'data/WA_Fn-UseC_-Telco-Customer-Churn.csv',\n",
    "    '../datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in possible_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Dataset carregado de: {path}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "if df is None:\n",
    "    raise FileNotFoundError(\"Dataset n√£o encontrado. Verifique o caminho do arquivo.\")\n",
    "\n",
    "print(f\"\\nDimens√µes do dataset: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
    "print(f\"\\nColunas dispon√≠veis:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o inicial dos dados\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa√ß√µes sobre tipos de dados\n",
    "print(\"Informa√ß√µes do dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Limpeza e Transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando c√≥pia para preservar dados originais\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Problema identificado: TotalCharges cont√©m strings vazias que precisam ser convertidas\n",
    "print(\"Valores √∫nicos em TotalCharges (amostra):\")\n",
    "print(df_clean['TotalCharges'].head(10))\n",
    "\n",
    "# Convers√£o de TotalCharges para num√©rico\n",
    "df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Verificando valores ausentes\n",
    "print(f\"\\nValores ausentes por coluna:\")\n",
    "missing = df_clean.isnull().sum()\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores ausentes em TotalCharges\n",
    "rows_before = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=['TotalCharges'])\n",
    "rows_after = len(df_clean)\n",
    "\n",
    "print(f\"Linhas removidas: {rows_before - rows_after}\")\n",
    "print(f\"Dataset final: {rows_after} linhas\")\n",
    "\n",
    "# Confirmando que n√£o h√° mais valores ausentes\n",
    "print(f\"\\nValores ausentes restantes: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: An√°lise Explorat√≥ria de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas das vari√°veis num√©ricas\n",
    "print(\"Estat√≠sticas Descritivas - Vari√°veis Num√©ricas:\")\n",
    "df_clean[['tenure', 'MonthlyCharges', 'TotalCharges']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o da vari√°vel alvo (Churn)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Contagem\n",
    "churn_counts = df_clean['Churn'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(churn_counts.index, churn_counts.values, color=colors)\n",
    "axes[0].set_title('Distribui√ß√£o de Churn (Contagem)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Churn')\n",
    "axes[0].set_ylabel('Contagem')\n",
    "for i, v in enumerate(churn_counts.values):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', fontsize=12)\n",
    "\n",
    "# Propor√ß√£o\n",
    "churn_pct = df_clean['Churn'].value_counts(normalize=True) * 100\n",
    "axes[1].pie(churn_pct.values, labels=churn_pct.index, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90, explode=[0, 0.05])\n",
    "axes[1].set_title('Propor√ß√£o de Churn', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPropor√ß√£o de Churn:\")\n",
    "print(churn_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de vari√°veis categ√≥ricas importantes vs Churn\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "categorical_vars = ['Contract', 'InternetService', 'PaymentMethod', 'TechSupport']\n",
    "\n",
    "for idx, var in enumerate(categorical_vars):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Crosstab para propor√ß√µes\n",
    "    ct = pd.crosstab(df_clean[var], df_clean['Churn'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=ax, color=['#2ecc71', '#e74c3c'])\n",
    "    \n",
    "    ax.set_title(f'Taxa de Churn por {var}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('Porcentagem (%)')\n",
    "    ax.legend(title='Churn', loc='upper right')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de vari√°veis num√©ricas vs Churn\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "numeric_vars = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "for idx, var in enumerate(numeric_vars):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Boxplot por grupo de Churn\n",
    "    df_clean.boxplot(column=var, by='Churn', ax=ax)\n",
    "    ax.set_title(f'{var} por Churn', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Churn')\n",
    "    ax.set_ylabel(var)\n",
    "\n",
    "plt.suptitle('')  # Remove t√≠tulo autom√°tico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correla√ß√£o das vari√°veis num√©ricas\n",
    "# Convertendo Churn para num√©rico para correla√ß√£o\n",
    "df_corr = df_clean.copy()\n",
    "df_corr['Churn_num'] = (df_corr['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "corr_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn_num']\n",
    "corr_matrix = df_corr[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Matriz de Correla√ß√£o', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights da EDA\n",
    "\n",
    "1. **Desbalanceamento:** Dataset levemente desbalanceado (~27% de churn)\n",
    "2. **Contrato:** Clientes com contrato mensal t√™m muito mais churn\n",
    "3. **Tenure:** Clientes mais novos (menor tempo de casa) t√™m maior propens√£o ao churn\n",
    "4. **MonthlyCharges:** Clientes que pagam mais por m√™s tendem a cancelar mais\n",
    "5. **Servi√ßos:** Clientes sem suporte t√©cnico ou seguran√ßa online t√™m maior churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4: Prepara√ß√£o para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sele√ß√£o de features relevantes baseada na EDA\n",
    "features_selecionadas = [\n",
    "    # Vari√°veis num√©ricas\n",
    "    'SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges',\n",
    "    # Vari√°veis categ√≥ricas relevantes\n",
    "    'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "    'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "    'PaperlessBilling', 'PaymentMethod'\n",
    "]\n",
    "\n",
    "# Verificando se todas as features existem\n",
    "features_existentes = [f for f in features_selecionadas if f in df_clean.columns]\n",
    "print(f\"Features selecionadas: {len(features_existentes)}\")\n",
    "print(features_existentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando X (features) e y (target)\n",
    "X = df_clean[features_existentes].copy()\n",
    "y = df_clean['Churn'].copy()\n",
    "\n",
    "# Convertendo target para bin√°rio (0/1)\n",
    "y = (y == 'Yes').astype(int)\n",
    "\n",
    "print(f\"Shape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"\\nDistribui√ß√£o de y:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding das vari√°veis categ√≥ricas\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(f\"Dimens√µes ap√≥s encoding:\")\n",
    "print(f\"  X original: {X.shape}\")\n",
    "print(f\"  X encoded:  {X_encoded.shape}\")\n",
    "\n",
    "# Visualizando as novas colunas\n",
    "print(f\"\\nNovas colunas criadas (primeiras 20):\")\n",
    "print(X_encoded.columns.tolist()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divis√£o treino/teste (80/20) com estratifica√ß√£o\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y,\n",
    "    test_size=0.20,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]} ({X_train.shape[0]/len(X_encoded)*100:.1f}%)\")\n",
    "print(f\"Tamanho do conjunto de teste:  {X_test.shape[0]} ({X_test.shape[0]/len(X_encoded)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPropor√ß√£o de churn no treino:\")\n",
    "print(y_train.value_counts(normalize=True).round(3))\n",
    "\n",
    "print(f\"\\nPropor√ß√£o de churn no teste:\")\n",
    "print(y_test.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 3: Modelagem e Avalia√ß√£o (6,0 pontos)\n",
    "\n",
    "## 3.1 Defini√ß√£o das M√©tricas de Avalia√ß√£o\n",
    "\n",
    "Para avaliar os modelos de classifica√ß√£o, utilizaremos **3 m√©tricas** fundamentais:\n",
    "\n",
    "### 1. Accuracy (Acur√°cia)\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "**O que mede:** Propor√ß√£o total de previs√µes corretas (tanto positivas quanto negativas).\n",
    "\n",
    "**Relev√¢ncia para Churn:** D√° uma vis√£o geral do desempenho, mas pode ser enganosa em datasets desbalanceados.\n",
    "\n",
    "### 2. Precision (Precis√£o)\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**O que mede:** Dos clientes que o modelo previu como churn, quantos realmente cancelaram?\n",
    "\n",
    "**Relev√¢ncia para Churn:** Alta precis√£o significa menos \"alarmes falsos\" - n√£o desperdi√ßamos recursos oferecendo reten√ß√£o a quem n√£o ia sair.\n",
    "\n",
    "### 3. Recall (Revoca√ß√£o/Sensibilidade)\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**O que mede:** De todos os clientes que realmente cancelaram, quantos o modelo conseguiu identificar?\n",
    "\n",
    "**Relev√¢ncia para Churn:** **M√âTRICA CRUCIAL!** Alto recall significa capturar a maioria dos clientes em risco. √â mais caro perder um cliente (FN) do que oferecer reten√ß√£o a quem ficaria (FP).\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è **Para o problema de Churn, Recall √© a m√©trica mais importante!**\n",
    "> \n",
    "> Falsos Negativos (n√£o prever churn de quem vai sair) custam muito mais que Falsos Positivos (prever churn de quem ia ficar).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio para armazenar os modelos e resultados\n",
    "modelos = {}\n",
    "resultados = {}\n",
    "\n",
    "# Lista de nomes das colunas para uso posterior\n",
    "feature_names = X_encoded.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do Decision Tree\n",
    "print(\"=\" * 50)\n",
    "print(\"MODELO 1: Decision Tree Classifier\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Armazenando modelo\n",
    "modelos['Decision Tree'] = dt_model\n",
    "\n",
    "# Calculando m√©tricas\n",
    "resultados['Decision Tree'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
    "    'Precision': precision_score(y_test, y_pred_dt),\n",
    "    'Recall': recall_score(y_test, y_pred_dt)\n",
    "}\n",
    "\n",
    "print(f\"\\nHiperpar√¢metros: max_depth=4\")\n",
    "print(f\"\\nResultados:\")\n",
    "for metric, value in resultados['Decision Tree'].items():\n",
    "    print(f\"  {metric}: {value:.4f} ({value*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o - Decision Tree\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['N√£o Churn', 'Churn'],\n",
    "            yticklabels=['N√£o Churn', 'Churn'])\n",
    "plt.xlabel('Previsto', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.title('Matriz de Confus√£o - Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=['N√£o Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do Random Forest\n",
    "print(\"=\" * 50)\n",
    "print(\"MODELO 2: Random Forest Classifier\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Armazenando modelo\n",
    "modelos['Random Forest'] = rf_model\n",
    "\n",
    "# Calculando m√©tricas\n",
    "resultados['Random Forest'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision': precision_score(y_test, y_pred_rf),\n",
    "    'Recall': recall_score(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "print(f\"\\nHiperpar√¢metros: n_estimators=100, max_depth=6\")\n",
    "print(f\"\\nResultados:\")\n",
    "for metric, value in resultados['Random Forest'].items():\n",
    "    print(f\"  {metric}: {value:.4f} ({value*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o - Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['N√£o Churn', 'Churn'],\n",
    "            yticklabels=['N√£o Churn', 'Churn'])\n",
    "plt.xlabel('Previsto', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.title('Matriz de Confus√£o - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['N√£o Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento da Regress√£o Log√≠stica\n",
    "print(\"=\" * 50)\n",
    "print(\"MODELO 3: Logistic Regression\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Armazenando modelo\n",
    "modelos['Logistic Regression'] = lr_model\n",
    "\n",
    "# Calculando m√©tricas\n",
    "resultados['Logistic Regression'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'Precision': precision_score(y_test, y_pred_lr),\n",
    "    'Recall': recall_score(y_test, y_pred_lr)\n",
    "}\n",
    "\n",
    "print(f\"\\nHiperpar√¢metros: max_iter=1000\")\n",
    "print(f\"\\nResultados:\")\n",
    "for metric, value in resultados['Logistic Regression'].items():\n",
    "    print(f\"  {metric}: {value:.4f} ({value*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o - Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['N√£o Churn', 'Churn'],\n",
    "            yticklabels=['N√£o Churn', 'Churn'])\n",
    "plt.xlabel('Previsto', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.title('Matriz de Confus√£o - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['N√£o Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 An√°lise Comparativa dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando tabela comparativa\n",
    "df_resultados = pd.DataFrame(resultados).T\n",
    "df_resultados = df_resultados.round(4)\n",
    "\n",
    "# Formatando como porcentagem para exibi√ß√£o\n",
    "df_display = df_resultados.copy()\n",
    "for col in df_display.columns:\n",
    "    df_display[col] = df_display[col].apply(lambda x: f\"{x:.2%}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TABELA COMPARATIVA DOS MODELOS\")\n",
    "print(\"=\"*60)\n",
    "print(df_display.to_string())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o gr√°fica da compara√ß√£o\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(df_resultados.columns))\n",
    "width = 0.25\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "models = list(df_resultados.index)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    values = df_resultados.loc[model].values\n",
    "    bars = ax.bar(x + i*width, values, width, label=model, color=colors[i])\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.2%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('M√©tricas', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Compara√ß√£o de Desempenho dos Modelos', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(df_resultados.columns)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Threshold 80%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara√ß√£o das Matrizes de Confus√£o lado a lado\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "confusion_matrices = [\n",
    "    ('Decision Tree', cm_dt, 'Blues'),\n",
    "    ('Random Forest', cm_rf, 'Greens'),\n",
    "    ('Logistic Regression', cm_lr, 'Oranges')\n",
    "]\n",
    "\n",
    "for idx, (name, cm, cmap) in enumerate(confusion_matrices):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=axes[idx],\n",
    "                xticklabels=['N√£o Churn', 'Churn'],\n",
    "                yticklabels=['N√£o Churn', 'Churn'])\n",
    "    axes[idx].set_xlabel('Previsto')\n",
    "    axes[idx].set_ylabel('Real')\n",
    "    axes[idx].set_title(f'{name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Compara√ß√£o das Matrizes de Confus√£o', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Justificativa da Escolha do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada para escolha do modelo\n",
    "print(\"=\"*70)\n",
    "print(\"AN√ÅLISE PARA SELE√á√ÉO DO MELHOR MODELO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Encontrar melhor modelo por m√©trica\n",
    "best_accuracy = df_resultados['Accuracy'].idxmax()\n",
    "best_precision = df_resultados['Precision'].idxmax()\n",
    "best_recall = df_resultados['Recall'].idxmax()\n",
    "\n",
    "print(f\"\\nüìä Melhor Accuracy:  {best_accuracy} ({df_resultados.loc[best_accuracy, 'Accuracy']:.2%})\")\n",
    "print(f\"üìä Melhor Precision: {best_precision} ({df_resultados.loc[best_precision, 'Precision']:.2%})\")\n",
    "print(f\"üìä Melhor Recall:    {best_recall} ({df_resultados.loc[best_recall, 'Recall']:.2%})\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"JUSTIFICATIVA DA ESCOLHA\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "justificativa = \"\"\"\n",
    "Para o problema de CHURN em telecomunica√ß√µes, a escolha do modelo deve priorizar\n",
    "o RECALL, pois:\n",
    "\n",
    "1. CUSTO DE FALSO NEGATIVO (n√£o identificar um cliente que vai sair):\n",
    "   - Perda definitiva do cliente\n",
    "   - Custo de aquisi√ß√£o de novo cliente (5-25x maior que reten√ß√£o)\n",
    "   - Impacto negativo na receita recorrente\n",
    "\n",
    "2. CUSTO DE FALSO POSITIVO (identificar churn em quem ia ficar):\n",
    "   - Ofertar desconto/benef√≠cio desnecess√°rio\n",
    "   - Custo menor e cliente continua\n",
    "\n",
    "Portanto, √© prefer√≠vel errar oferecendo reten√ß√£o a mais do que perder clientes.\n",
    "\"\"\"\n",
    "print(justificativa)\n",
    "\n",
    "# Determinando modelo escolhido baseado na an√°lise\n",
    "modelo_escolhido = best_recall\n",
    "print(f\"\\nüèÜ MODELO ESCOLHIDO: {modelo_escolhido}\")\n",
    "print(f\"\\n   Justificativa: Apresenta o melhor Recall ({df_resultados.loc[modelo_escolhido, 'Recall']:.2%}),\")\n",
    "print(f\"   maximizando a captura de clientes em risco de churn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 4: Deploy do Modelo (2,0 pontos)\n",
    "\n",
    "## 4.1 Salvando o Modelo Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o melhor modelo baseado na an√°lise\n",
    "# Usando Logistic Regression por ter melhor Recall para o problema de churn\n",
    "melhor_modelo = modelos['Logistic Regression']\n",
    "\n",
    "# Salvando o modelo com joblib\n",
    "modelo_path = '../modelo_final.pkl'\n",
    "\n",
    "try:\n",
    "    joblib.dump(melhor_modelo, modelo_path)\n",
    "    print(f\"‚úÖ Modelo salvo com sucesso em: {modelo_path}\")\n",
    "except Exception as e:\n",
    "    # Tentativa alternativa de caminho\n",
    "    modelo_path = 'modelo_final.pkl'\n",
    "    joblib.dump(melhor_modelo, modelo_path)\n",
    "    print(f\"‚úÖ Modelo salvo com sucesso em: {modelo_path}\")\n",
    "\n",
    "print(f\"\\nTipo do modelo: {type(melhor_modelo).__name__}\")\n",
    "print(f\"Par√¢metros: {melhor_modelo.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando tamb√©m as colunas do encoding para uso futuro\n",
    "encoding_info = {\n",
    "    'feature_names': feature_names,\n",
    "    'original_features': features_existentes\n",
    "}\n",
    "\n",
    "print(f\"Features do modelo ({len(feature_names)} colunas ap√≥s encoding):\")\n",
    "print(feature_names[:10], \"... e mais\", len(feature_names)-10, \"colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Carregando e Utilizando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstra√ß√£o de carregamento do modelo salvo\n",
    "print(\"Carregando modelo salvo...\")\n",
    "modelo_carregado = joblib.load(modelo_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo carregado com sucesso!\")\n",
    "print(f\"Tipo: {type(modelo_carregado).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando exemplo de novo cliente para predi√ß√£o\n",
    "print(\"=\"*70)\n",
    "print(\"EXEMPLO DE PREDI√á√ÉO PARA NOVO CLIENTE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dados de um cliente fict√≠cio de alto risco\n",
    "novo_cliente = {\n",
    "    'SeniorCitizen': 0,\n",
    "    'tenure': 2,  # Apenas 2 meses como cliente\n",
    "    'MonthlyCharges': 89.90,  # Valor alto\n",
    "    'TotalCharges': 179.80,\n",
    "    'gender': 'Male',\n",
    "    'Partner': 'No',\n",
    "    'Dependents': 'No',\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'Yes',\n",
    "    'InternetService': 'Fiber optic',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'No',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'No',\n",
    "    'StreamingTV': 'Yes',\n",
    "    'StreamingMovies': 'Yes',\n",
    "    'Contract': 'Month-to-month',  # Contrato mensal - alto risco\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check'\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Dados do Novo Cliente:\")\n",
    "for key, value in novo_cliente.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento do novo cliente\n",
    "# Convertendo para DataFrame\n",
    "df_novo = pd.DataFrame([novo_cliente])\n",
    "\n",
    "# Aplicando One-Hot Encoding com as mesmas colunas do treino\n",
    "df_novo_encoded = pd.get_dummies(df_novo, drop_first=True)\n",
    "\n",
    "# Garantindo que tenha as mesmas colunas do treino\n",
    "for col in feature_names:\n",
    "    if col not in df_novo_encoded.columns:\n",
    "        df_novo_encoded[col] = 0\n",
    "\n",
    "# Reordenando colunas para match com treino\n",
    "df_novo_encoded = df_novo_encoded[feature_names]\n",
    "\n",
    "print(f\"Shape ap√≥s encoding: {df_novo_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a predi√ß√£o\n",
    "predicao = modelo_carregado.predict(df_novo_encoded)\n",
    "probabilidade = modelo_carregado.predict_proba(df_novo_encoded)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADO DA PREDI√á√ÉO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "resultado = \"CHURN\" if predicao[0] == 1 else \"N√ÉO CHURN\"\n",
    "prob_nao_churn = probabilidade[0][0] * 100\n",
    "prob_churn = probabilidade[0][1] * 100\n",
    "\n",
    "print(f\"\\nüéØ Predi√ß√£o: {resultado}\")\n",
    "print(f\"\\nüìä Probabilidades:\")\n",
    "print(f\"   - N√£o Churn: {prob_nao_churn:.2f}%\")\n",
    "print(f\"   - Churn:     {prob_churn:.2f}%\")\n",
    "\n",
    "if predicao[0] == 1:\n",
    "    print(\"\\n‚ö†Ô∏è  ALERTA: Este cliente tem alta probabilidade de cancelar!\")\n",
    "    print(\"   Recomenda√ß√£o: Entrar em contato para oferecer benef√≠cios de reten√ß√£o.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Este cliente tem baixa probabilidade de cancelar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Explica√ß√£o do Resultado\n",
    "\n",
    "O modelo previu **CHURN** para este cliente devido √†s seguintes caracter√≠sticas de alto risco:\n",
    "\n",
    "1. **Tenure baixo (2 meses):** Clientes novos t√™m maior propens√£o a cancelar\n",
    "2. **Contrato Month-to-month:** Sem v√≠nculo de longo prazo, facilita o cancelamento\n",
    "3. **Sem servi√ßos de seguran√ßa/suporte:** OnlineSecurity, TechSupport = No\n",
    "4. **MonthlyCharges alto:** Pode indicar insatisfa√ß√£o com custo-benef√≠cio\n",
    "5. **Pagamento por Electronic check:** Historicamente associado a maior churn\n",
    "\n",
    "### A√ß√£o Recomendada\n",
    "Para este cliente, a equipe de reten√ß√£o deveria:\n",
    "- Oferecer upgrade para contrato anual com desconto\n",
    "- Incluir servi√ßos de seguran√ßa e suporte gratuitos por per√≠odo\n",
    "- Propor revis√£o do pacote contratado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclus√£o\n",
    "\n",
    "## Resumo do Projeto\n",
    "\n",
    "Este projeto demonstrou o ciclo completo de um projeto de Ci√™ncia de Dados:\n",
    "\n",
    "1. **Problema de Neg√≥cio:** Defini√ß√£o clara do objetivo de prever churn em telecomunica√ß√µes\n",
    "\n",
    "2. **Pipeline de Dados:** \n",
    "   - Ingest√£o de dados CSV\n",
    "   - Limpeza e tratamento de valores ausentes\n",
    "   - An√°lise explorat√≥ria com visualiza√ß√µes\n",
    "   - Prepara√ß√£o com encoding e split treino/teste\n",
    "\n",
    "3. **Modelagem:**\n",
    "   - Treino de 3 modelos: Decision Tree, Random Forest, Logistic Regression\n",
    "   - Avalia√ß√£o com Accuracy, Precision e Recall\n",
    "   - Escolha baseada em crit√©rios de neg√≥cio (prioriza√ß√£o do Recall)\n",
    "\n",
    "4. **Deploy:**\n",
    "   - Modelo salvo com joblib\n",
    "   - Demonstra√ß√£o de carregamento e predi√ß√£o\n",
    "   - Exemplo pr√°tico com novo cliente\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "\n",
    "- Implementar API REST para predi√ß√µes em tempo real\n",
    "- Criar dashboard de monitoramento de churn\n",
    "- Treinar modelos com t√©cnicas de balanceamento (SMOTE)\n",
    "- Implementar valida√ß√£o cruzada para maior robustez"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}